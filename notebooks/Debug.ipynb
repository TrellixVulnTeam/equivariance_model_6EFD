{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZbrYjvKvkaH"
   },
   "source": [
    "# Debug notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KX2t25zgvkaf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.utils.data as tud\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from sklearn.metrics import jaccard_score\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "sys.path.insert(1, '../datasets')\n",
    "sys.path.insert(1, '../utils_on_gpu')\n",
    "import coco_utils as cu\n",
    "import my_datasets as mdset\n",
    "import eval_train as ev\n",
    "import utils as U\n",
    "import find_best_model as fbm   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aw2xTNEkvka0"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzkSq_mgrcLR"
   },
   "outputs": [],
   "source": [
    "#MODEL SAVE AND LOAD \n",
    "dataroot_voc = '/share/DEEPLEARNING/datasets/voc2012'\n",
    "dataroot_sbd = '/share/DEEPLEARNING/datasets/sbd'\n",
    "dataroot_coco = '/share/DEEPLEARNING/datasets/coco'\n",
    "dataroot_coco2voc = '/users/k/karmimy/data/coco2voc'\n",
    "load_dir = '/share/homes/karmimy/equiv/save_model/fully_supervised' #load a particular model \n",
    "fcn= True\n",
    "pretrained=True\n",
    "\n",
    "# GPU \n",
    "gpu = 3\n",
    "# TRAIN PARAMETERS\n",
    "batch_size = 2\n",
    "gamma = 0.5\n",
    "learning_rate = 10e-4\n",
    "moment = 0.9\n",
    "wd = 2e-4\n",
    "\n",
    "\n",
    "# LOSS \n",
    "\n",
    "criterion_supervised = nn.CrossEntropyLoss(ignore_index=21) # On ignore la classe border.\n",
    "Loss = 'KL' # Loss = 'KL' or 'CE' or None for L1,MSEâ€¦\n",
    "criterion_unsupervised = U.get_criterion(Loss)\n",
    "\n",
    "\n",
    "# DATASET AND DATA AUG \n",
    "rotate = False # random rotation during training\n",
    "scale = True\n",
    "split = True # split the supervised dataset\n",
    "ratio = 0.3 # percent of data of VOC + SBD we use for supervised dataset\n",
    "#scale_factor = (0.2,0.8)\n",
    "#size_img = (420,420) \n",
    "#size_crop = (380,380)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AAj55UZxOZte",
    "outputId": "9257ab6a-d935-4c69-ddf6-ea40effa907a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using downloaded and verified file: /share/DEEPLEARNING/datasets/voc2012/VOCtrainval_11-May-2012.tar\n",
      "Using downloaded and verified file: /share/DEEPLEARNING/datasets/voc2012/VOCtrainval_11-May-2012.tar\n"
     ]
    }
   ],
   "source": [
    "train_dataset_VOC = mdset.VOCSegmentation(dataroot_voc,year='2012', image_set='train', \\\n",
    "        download=True,rotate=rotate,scale=scale)#,size_img=size_img,size_crop=size_crop)\n",
    "val_dataset_VOC = mdset.VOCSegmentation(dataroot_voc,year='2012', image_set='val', download=True)\n",
    "train_dataset_SBD = mdset.SBDataset(dataroot_sbd, image_set='train_noval',mode='segmentation',\\\n",
    "        rotate=rotate,scale=scale)#,size_img=size_img,size_crop=size_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,m=train_dataset_VOC.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0,  1, 15])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "torch.unique(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LUqeDj5hvka3",
    "outputId": "92a782a5-3bc5-48f5-b57a-af5993c9c201"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device : cuda:3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataloader_train_VOC = torch.utils.data.DataLoader(train_dataset_VOC, batch_size=batch_size,\\\n",
    "                                                       shuffle=True,drop_last=True)\n",
    "#dataloader_train_sup = torch.utils.data.DataLoader(train_dataset_sup, batch_size=batch_size,\\\n",
    "#                                                       shuffle=True,drop_last=True)\n",
    "#dataloader_train_equiv = torch.utils.data.DataLoader(train_dataset_unsup,batch_size=batch_size,\\\n",
    "#                                                     shuffle=True,drop_last=True)\n",
    "\n",
    "dataloader_val = torch.utils.data.DataLoader(val_dataset_VOC, batch_size=batch_size)\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:\"+str(gpu) if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device :\",device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "63IQP70Qg8BL",
    "outputId": "e38a98ff-0b99-4e3a-eae4-bdf29ddf3636",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Taille dataset train supervised : 2126\n",
      "Taille dataset train unsupervised : 7087\n",
      "Taille dataset val VOC : 1449\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille dataset train supervised :\",len(train_dataset_sup))\n",
    "print(\"Taille dataset train unsupervised :\",len(train_dataset_unsup))\n",
    "print(\"Taille dataset val VOC :\",len(val_dataset_VOC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tl0nR2NJ8I2i"
   },
   "source": [
    "\n",
    "## FCN Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file=None,fcn=False,pretrained=False):\n",
    "    if file is None:\n",
    "        if fcn is False:\n",
    "            model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=pretrained)\n",
    "        else:\n",
    "            model = torchvision.models.segmentation.fcn_resnet101(pretrained=pretrained)\n",
    "    else:\n",
    "        model = torch.load(os.path.join(SAVE_DIR,file))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(file=None,fcn=fcn,pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "N3HOA_uv8Oyd",
    "outputId": "c886c10b-558e-4acb-a2ac-b2110fddc29f"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       ")\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQeaeCk1hsGu"
   },
   "source": [
    "## Test Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=moment, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train_equiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,m = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "142\nCrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "min_f,max_f = scale_factor\n",
    "factor = random.uniform(min_f,max_f) \n",
    "size = int(size_img[0] * factor)\n",
    "print(size)\n",
    "print(criterion_unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_equiv,acc = U.compute_scale_equiv_batch(x,model,size=(size,size),\\\n",
    "                                                     criterion=criterion_unsupervised,Loss = Loss,\\\n",
    "                                                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(2.6292, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "loss_equiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Target 17 is out of bounds.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fc08af42665a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 17 is out of bounds."
     ]
    }
   ],
   "source": [
    "loss_sup = criterion_supervised(x,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "uda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7025, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2171, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7064, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4618, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2515, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.9837, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.1176, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3035, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7732, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5384, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3183, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7927, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5555, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4958, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5846, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5402, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2326, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3038, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2682, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4130, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3009, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3569, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2397, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4226, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3312, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4303, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5683, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4993, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4091, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3381, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3736, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2774, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.4905, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8839, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1881, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.2533, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2207, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3918, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.2373, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8145, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2797, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5911, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4354, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4009, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.3633, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8821, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4394, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(2.7402, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.5898, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1958, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5415, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3686, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3877, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5533, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4705, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2453, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4529, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3491, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2443, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.2483, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2463, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3742, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.9051, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6397, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2839, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(2.2749, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.2794, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1578, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(2.6814, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.4196, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3219, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5989, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4604, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4004, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7661, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5832, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.8972, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.6513, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.2742, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5691, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.8422, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.2057, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2360, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0875, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6617, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4592, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.8966, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6779, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3812, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.8655, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.1234, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2806, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6705, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4755, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5085, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6172, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5629, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5862, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5604, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5733, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.7278, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.3927, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.0602, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3445, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.1609, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7527, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4081, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7184, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5632, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4109, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4159, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4134, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5641, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.8562, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.2102, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.6078, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4038, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5058, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2885, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7955, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5420, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4105, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7614, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5860, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3940, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(2.3834, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.3887, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3185, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4410, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3797, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2088, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.8979, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5533, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4100, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3107, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3603, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2086, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.4327, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8207, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1243, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.2640, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.1941, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5779, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4767, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5273, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4025, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6493, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5259, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1803, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.4573, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8188, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5029, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5350, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5189, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2217, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.2261, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2239, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2841, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3635, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3238, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2508, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6964, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4736, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2138, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3447, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2793, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2213, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0543, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6378, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3418, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.8452, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5935, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1568, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0104, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5836, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4367, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3124, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3746, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2631, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.4218, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8425, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4913, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0275, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7594, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2951, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4498, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3725, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5752, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.2726, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4239, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3548, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0257, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6902, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2392, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.8602, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5497, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2098, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6192, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4145, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1683, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6200, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3942, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2309, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.9065, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5687, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3092, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.2066, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7579, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1516, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5816, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3666, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2995, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.1801, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2398, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2088, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3425, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2756, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2248, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.1518, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.1883, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3545, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.7297, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5421, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1481, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4686, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3084, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.7294, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.3585, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.0440, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1857, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(2.6306, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.4082, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3425, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4097, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3761, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2528, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5502, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4015, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2603, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4604, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3604, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4799, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3062, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3931, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3392, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0265, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6829, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2796, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4436, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3616, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1803, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3625, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2714, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2717, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0710, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6713, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3025, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3092, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3059, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3370, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.0578, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.6974, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4583, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4204, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4393, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2939, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.2879, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7909, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5902, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(3.0610, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.8256, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.4485, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4656, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4571, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.5636, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3813, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4724, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3222, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.1097, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7159, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2199, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.6409, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4304, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1784, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.3547, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7666, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3262, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.9699, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(1.1481, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3358, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(3.8830, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(2.1094, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3780, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.2070, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2925, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2365, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.4427, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8396, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1970, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3340, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.2655, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2987, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3251, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3119, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.1673, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.5560, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.8616, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3645, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3114, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3379, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3141, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.4509, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.3825, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.3386, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.5394, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.4390, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.2980, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(1.1925, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.7453, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "loss equiv tensor(0.6849, grad_fn=<NllLoss2DBackward>)\n",
      "loss_sup tensor(0.3404, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n",
      "loss tensor(0.5127, device='cuda:1', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch_sup,batch_unsup in zip(dataloader_train_sup,dataloader_train_equiv):\n",
    "    optimizer.zero_grad()\n",
    "    min_f,max_f = scale_factor\n",
    "    factor = random.uniform(min_f,max_f) \n",
    "    size = int(size_img[0] * factor)\n",
    "    x_unsup,_ = batch_unsup\n",
    "    loss_equiv,acc = U.compute_scale_equiv_batch(x_unsup,model,size=(size,size),\\\n",
    "                                                criterion=criterion_unsupervised,Loss = Loss,\\\n",
    "                                                device=device)\n",
    "    print('loss equiv',loss_equiv)\n",
    "    x,mask = batch_sup\n",
    "    x = x.to(device)\n",
    "    mask = mask.to(device)\n",
    "    pred = model(x)[\"out\"]\n",
    "    loss_equiv = loss_equiv.to(device) # otherwise bug in combining the loss \n",
    "    loss_sup = criterion_supervised(pred,mask)\n",
    "    print('loss_sup',loss_sup)\n",
    "    loss = gamma*loss_sup + (1-gamma)*loss_equiv # combine loss \n",
    "    print('loss',loss)             \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAUmF-R0B6U0"
   },
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FCN_seg2012.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}